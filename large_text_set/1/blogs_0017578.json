{"organizations": [], "uuid": "13a23811f19ff5a5642603334a0665e4119e4c78", "thread": {"social": {"gplus": {"shares": 0}, "pinterest": {"shares": 0}, "vk": {"shares": 0}, "linkedin": {"shares": 2}, "facebook": {"likes": 300, "shares": 300, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "www.reddit.com", "main_image": "http://b.thumbs.redditmedia.com/gN4JlJ1UDGLL5q_sOo-fozyfsVRJviZ4tkVLHxxSGfw.jpg", "site_section": "https://www.reddit.com/.rss", "section_title": "reddit: the front page of the internet", "url": "https://www.reddit.com/r/science/comments/5pkewb/study_facebook_can_actually_make_us_more/", "country": "US", "domain_rank": 33, "title": "Study: Facebook can actually make us more narrow-minded", "performance_score": 3, "site": "reddit.com", "participants_count": 1, "title_full": "Study: Facebook can actually make us more narrow-minded", "spam_score": 0.0, "site_type": "blogs", "published": "2017-01-23T06:01:00.000+02:00", "replies_count": 0, "uuid": "13a23811f19ff5a5642603334a0665e4119e4c78"}, "author": "/u/keldohead", "url": "https://www.reddit.com/r/science/comments/5pkewb/study_facebook_can_actually_make_us_more/", "ord_in_thread": 0, "title": "Study: Facebook can actually make us more narrow-minded", "locations": [], "entities": {"persons": [], "locations": [{"name": "reddit", "sentiment": "none"}], "organizations": [{"name": "facebook", "sentiment": "negative"}, {"name": "wef", "sentiment": "none"}]}, "highlightText": "", "language": "english", "persons": [], "text": "[–] EdwardDupont 60 points 61 points 62 points 4 hours ago (6 children) \nPutting the Conclusion first so anyone can get the gist of it. Below the conclusion are some specific parts I wanted to high light and some of what I believe happens to all of us. The important thing here with the study is trying to catch yourself falling victim to homogeneity. \nConclusions \nDigital misinformation has become so pervasive in online social media that it has been listed by the WEF as one of the main threats to human society. Whether a news item, either substantiated or not, is accepted as true by a user may be strongly affected by social norms or by how much it coheres with the user’s system of beliefs (32, 33). Many mechanisms cause false information to gain acceptance, which in turn generate false beliefs that, once adopted by an individual, are highly resistant to correction (34⇓⇓–37). In this work, using extensive quantitative analysis and data-driven modeling, we provide important insights toward the understanding of the mechanism behind rumor spreading. Our findings show that users mostly tend to select and share content related to a specific narrative and to ignore the rest. In particular, we show that social homogeneity is the primary driver of content diffusion, and one frequent result is the formation of homogeneous, polarized clusters. Most of the times the information is taken by a friend having the same profile (polarization)––i.e., belonging to the same echo chamber. \nPeople like drama. \nScience news is usually assimilated, i.e., it reaches a higher level of diffusion quickly, and a longer lifetime does not correspond to a higher level of interest. \nConversely, conspiracy rumors are assimilated more slowly and show a positive relation between lifetime and size. \nAlso another very important thing to see. \nContents tend to circulate only inside the echo chamber \nEcho chambers in this case are science and conspiracy. \nhomogeneity is clearly the driver of information diffusion. In other words, different contents generate different echo chambers, characterized by a high level of homogeneity inside them. \nSo we have a bunch of information being circulated on Reddit and Facebook. You take what you like and circulate it among your peers, friends, family while unsubscribing from other things you don't like. Here begins the homogeneity and its diffusion. You and I surround ourselves with what we like through unconscious bias and then to confirmation bias as seen below. \nFrom the model: \nOur findings show that users mostly tend to select and share content according to a specific narrative and to ignore the rest. This suggests that the determinant for the formation of echo chambers is confirmation bias. \nAt each step the news items are diffused and initially shared by a group of first sharers. After the first step, the news recursively passes to the neighborhoods of previous step sharers, e.g., those of the first sharers during the second step. If a friend of the previous step sharers has an opinion close to the fitness of the news, then she shares the news again. \nI'm not particularly sure what they mean by \"opinion\" and in the regards of being positive or negative. Depending on the person, he or she may tend to share what they believe is positive news but also potentially share more news that has a negative opinion. I'm not sure why they left that key out. Maybe I missed it somewhere. \nThis is kind of funny. \nFrequently troll information, e.g., parodies of conspiracy theories such as chem-trails containing the active principle of Viagra, is picked up and shared by habitual conspiracy theory consumers \nWhat worries me is that there are actually habitual conspiracy theory consumers. This mindset is addictive. My roommate went down this wormhole and basically anything and everything is made up, trusting no one but the ones that were preaching to his beliefs. Anyone who didn't believe him or the others was \"stupid\". It's like being in a bad relationship with a girlfriend or boyfriend and you don't see it until you break up or change something. It's very difficult to leave your bias. Recognize it and try to work on it.", "external_links": [], "published": "2017-01-23T06:01:00.000+02:00", "crawled": "2017-01-23T09:12:42.751+02:00", "highlightTitle": ""}