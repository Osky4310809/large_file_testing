{"organizations": [], "uuid": "3fd5bd7acb26c3130d732084eff73187a0404a7e", "thread": {"social": {"gplus": {"shares": 3}, "pinterest": {"shares": 0}, "vk": {"shares": 0}, "linkedin": {"shares": 0}, "facebook": {"likes": 776, "shares": 776, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "www.pcgamer.com", "main_image": "http://cdn.mos.cms.futurecdn.net/p76xDCSer4EjDifgkkGPRi-1200-80.jpg", "site_section": "http://www.pcgamer.com/rss", "section_title": "PC Gamer", "url": "http://www.pcgamer.com/geforce-gtx-1080-ti-review/", "country": "GB", "domain_rank": 2091, "title": "GeForce GTX 1080 Ti review in progress", "performance_score": 7, "site": "pcgamer.com", "participants_count": 0, "title_full": "GeForce GTX 1080 Ti review in progress", "spam_score": 0.0, "site_type": "blogs", "published": "2017-03-09T21:00:00.000+02:00", "replies_count": 0, "uuid": "3fd5bd7acb26c3130d732084eff73187a0404a7e"}, "author": "", "url": "http://www.pcgamer.com/geforce-gtx-1080-ti-review/", "ord_in_thread": 0, "title": "GeForce GTX 1080 Ti review in progress", "locations": [], "entities": {"persons": [{"name": "pascal", "sentiment": "none"}, {"name": "jarred walton jarred", "sentiment": "none"}, {"name": "ti", "sentiment": "none"}, {"name": "vega", "sentiment": "none"}], "locations": [{"name": "zotac", "sentiment": "none"}], "organizations": [{"name": "gpu", "sentiment": "negative"}, {"name": "msi", "sentiment": "none"}, {"name": "nvidia", "sentiment": "none"}, {"name": "evga", "sentiment": "none"}, {"name": "lpc", "sentiment": "none"}, {"name": "pny", "sentiment": "none"}, {"name": "amd", "sentiment": "none"}, {"name": "cuda", "sentiment": "none"}, {"name": "fxaa", "sentiment": "none"}, {"name": "falcon northwest tiki", "sentiment": "none"}, {"name": "asus", "sentiment": "none"}, {"name": "smaa", "sentiment": "none"}, {"name": "quadro", "sentiment": "none"}, {"name": "commodore", "sentiment": "none"}]}, "highlightText": "", "language": "english", "persons": [], "text": "Pushing single GPU performance to new heights. Shares \nThird time's the charm? You bet it is. Dating back to the 700 series, Nvidia has followed a pattern for GPU launches. First come the high-end x80 and x70 cards, at very high prices. Then the x60 and x50 models trickle out over the coming months, and somewhere along the way will be a new uber-performant and uber-expensive Titan card. But as fast as the Titan might be in games, you really shouldn't buy one (unless money is no object and you simply have to have the fastest hardware around *cough* LPC *cough* ), because inevitably the Titan will end up being challenged by an upstart. Much as the Greek gods overthrew the Titans, every generation the x80 Ti card ends up as the far better value. \nThat isn't to say the Titan cards suddenly become useless. The original GTX Titan featured full performance FP64 support, something Nvidia usually doesn't provide unless you buy a Quadro or Tesla card. The Titan cards have previously come with more VRAM—twice as much as the 780 Ti and 980 Ti. But this round, Nvidia is apparently pulling out all the stops, with a new 1080 Ti that eclipses the Titan X (Pascal, aka Titan XP) in pretty much every meaningful way. \nCUDA core counts are the same, and with higher clockspeeds that means the 1080 Ti has more raw computational performance. The memory is also GDDR5X, dialed all the way up to 11Gbps (vs. 10Gbps on the Titan XP), and while there's technically 1GB less VRAM and a slightly narrower 352-bit bus (vs. 384-bit), the 1080 Ti still has a bit more memory bandwidth. In fact the only place where the Titan XP wins out is in VRAM quantity, but even then it's only 12GB vs. 11GB—hardly a large enough gap to worry about. \nI have a theory about why Nvidia went all-in on the 1080 Ti, and it's pretty simple: Nvidia will not let AMD claim the top spot for consumer graphics cards with Vega, not even for a few weeks or even days. R9 290X was the last time AMD had a viable claim to beating Nvidia's best, and the 780 Ti mostly solved that problem. The 980 Ti preempted the Fury X by a few weeks and delivered about 10 percent higher performance, with more VRAM as an added bonus. Vega should be at least 40 percent faster than the Fury X, probably even 50 percent faster, which would put it ahead of the GTX 1080. So here we are, a couple months before RX Vega hits retail, and Nvidia drops the 1080 Ti bomb. \nAs with the prior top-shelf Ti cards, GTX 1080 Ti looks an awful lot like the Titan XP, with silver accents instead of going for an all-black cooling shroud. It also looks virtually identical to the GTX 1080 FE, except with an extra 6-pin PCIe connector and without a native DVI output. Nvidia says the actual vapor chamber is improved relative to the GTX 1080, but to the naked eye there's no visible difference. \nWith both the GTX 1080 Ti and Titan XP using the same GP102 GPU with 3,584 CUDA cores enabled, clock speeds play an important role. And even more importantly, Nvidia's 'typical boost clock' figures are very conservative. If you run something like Furmark or an extremely computationally intensive GPGPU workload, yeah, the typical boost clock may be around 1582MHz. In practice, even after leaving games running for several hours, the actual GPU clockspeed is often in the 1700-1800MHz range. That's using a fully stock setup. It's Nvidia's way of making customers feel like they got something extra—you'll almost always meet or exceed the 'typical boost' speed in my experience. And I have to say, I personally find this approach a lot more appealing than the 'up to' clockspeed numbers seen on other products. The new ruler of Mount Olympus \nIf you want to know a bit more about what makes the GTX 1080 Ti tick, check my earlier article on the subject (or come back later today when I'll have had more time to include some of the other information). But I know most of you are just interested in seeing how the GTX 1080 Ti performs. So for now, I present you with a full suite of sixteen games, tested at four setting/resolution combinations. I've omitted most of the older cards, since I haven't had a chance to go back and retest them with the latest drivers and game versions. For reference, the GTX 1070 tends to be roughly equal to the GTX 980 Ti, slightly faster in some cases. \nOh, and you won't find any comparisons with the Titan XP here. Why? Because I never actually got a review sample—Nvidia said the card wasn't intended for gamers, and apparently that meant not for PC Gamer either. We did some limited testing of the Titan XP last year in a Falcon Northwest Tiki, and there are two liquid-cooled Titans sitting in the LPC, but I don't have one available for testing and I'm not local to PCG HQ. Sorry about that. But there's no reason to expect Titan XP will be more than a few percent slower—it's basically the more expensive fraternal twin to the 1080 Ti, and just happened to be born first. Image 1 of 18 Geometric mean of sixteen games (not including Ghost Recon Wildlands). All games were tested using the best API, DX11 or DX12, for each vendor. Image 2 of 18 Medium uses 1080p normal preset, with extreme preset used on 1080p/1440p/4K. DX12 used for all cards. Image 3 of 18 Tested with medium preset at 1080p, and ultra preset at 1080p/1440p/4K. DX12 used for AMD, DX11 for Nvidia. Note that the game has a 200 fps cap. Image 4 of 18 Tested with medium preset and no AA at 1080p, and ultra preset at 1080p/1440p/4K with 4xMSAA. DX12 used for all cards. Image 5 of 18 Tested with medium preset at 1080p, and very high preset at 1080p/1440p/4K with no MSAA. DX12 used for AMD, DX11 for Nvidia. Image 6 of 18 Tested with medium preset at 1080p, and ultra preset at 1080p/1440p/4K. Note that the game has a 120 fps cap. Image 7 of 18 Tested with medium preset at 1080p, ultra preset at 1080p/1440p, and high preset at 4K. DX12 used for all cards. Image 8 of 18 Tested with medium preset and FXAA at 1080p, and ultra preset with SMAA at 1080p/1440p/4K. Vulkan API used for all cards. Note that the game has a 200 fps cap. Image 9 of 18 Tested with medium preset at 1080p, and ultra preset at 1080p/1440p/4K. iPresentInterval set to 0, which results in accelerated game speed above 144 fps. Image 10 of 18 Tested with medium preset at 1080p, and ultra preset at 1080p/1440p/4K. Image 11 of 18 Tested with medium preset at 1080p, and ultra preset at 1080p/1440p/4K. DX12 / Windows 10 is required. Image 12 of 18 Tested with all adjustable settings on 'normal at 1080p, and all settings at max (very high / ultra) with 4xMSAA at 1080p/1440p. 4K tested without 4xMSAA. Image 13 of 18 Tested with everything set to 'medium' at 1080p with FXAA, and everything at max (no SSAA) for 1080p/1440p/4K. DX12 used for all cards. Image 14 of 18 Tested with medium preset and FXAA at 1080p, very high with SMAA at 1080p/1440p, and high with FXAA at 4K. DX12 used for all cards. Image 15 of 18 Tested with medium preset and at 1080p, and ultra preset at 1080p/1440p/4K. Note that Nvidia's current drivers have some performance anomalies on certain cards. Image 16 of 18 Tested with medium preset and at 1080p, and ultra preset at 1080p/1440p/4K. DX12 used for AMD, DX11 for Nvidia. Image 17 of 18 Tested with medium preset (also on post processing), and ultra preset with HairWorks disabled at 1080p/1440p/4K. Image 18 of 18 Tested with medium preset at 1080p, and ultra preset at 1080p/1440p/4K. Ultra is too much for most GPUs right now, obviously. This game was not included in the overall average score, due to its newness. \nI'll be back later with more commentary, including overclocking results. For now, the 1080 Ti does exactly what Nvidia claimed it would: it beats the GTX 1080 by over 30 percent on average. But that's only when you're running games and settings that tax the GPU and don't hit CPU or system bottlenecks. There are a few instances where the lead is closer to 20 percent, even at 4K, and Civilization VI is still CPU limited at 4K Ultra with 4xMSAA—even 8xMSAA doesn't change things much. The biggest lead comes in The Division, where the Ti is 42 percent faster. \nDrop from 4K ultra (high in a few games) to 1440p ultra and the CPU and system become an even greater bottleneck. Now the Ti is only averaging about 25 percent more performance across my test suite. And at 1080p ultra the gap closes to 15 percent—not that you'd really expect anything less. \nSomething else to note is that of the sixteen games I tested, there are only two where AMD's current fastest graphics card, the R9 Fury X, can break into the top three, Deus Ex and Doom. Everywhere else, Nvidia lays claim to the full podium. AMD's RX Vega will hopefully shake things up a bit, and it's desperately needed. \nBut does that mean the 1080 Ti is capable of running any and every current game at 4K ultra settings and 60+ fps? No. Because there are still beastly games like Deus Ex, which even with the very high preset only manages 43 fps—without 4xMSAA. Another game in that same ballpark is Ghost Recon Wildlands, at least in its just-launched state, which averages just 37 fps on the 1080 Ti at 4K using the ultra preset. \nI didn't include Wildlands in the overall average because it's still too new, and clearly there's optimization work to be done, particularly for AMD GPUs. To get above 60 fps average at 4K in the built-in benchmark, even the 1080 Ti needs to drop to the medium preset. Ouch. But most of the other games in my test suite are very close to 60 fps at 4K, and one or two small tweaks would easily push it over that threshold. \nThe GTX 1080 Ti isn't just about raw performance, it's about retail pricing and widespread availability. Where the Titan X is a $1,200 card that's only available directly from Nvidia or through select system vendors, the GTX 1080 Ti is a $699 card and it will ship through all of the usual Nvidia graphics card partners— Asus, EVGA, Gigabyte, MSI, PNY, Zotac, and others . That means more competition, custom cooling solutions, and more variation in pricing. And while the 1080 Ti will initially launch with Founders Edition models, the Founders Edition has the same MSRP as the custom cards. \nWith the 1080 Ti taking over the $699 spot from the GTX 1080 FE, Nvidia has dropped prices on their other cards as well. The GTX 1080 now has a $499 MSRP, though factory OC models may still cost more. Prices have also come down on GTX 1070, with cards starting at $349 now. The 1060 and lower models don't appear to have changed in pricing, but they're in a completely different performance league. What that means in terms of value for your money is that performance scales almost directly with pricing. The 1080 costs 43 percent more than the 1070 and outperforms it by about 25 percent—not perfectly linear scaling, but much better than the previous 60 percent price premium. The 1080 Ti meanwhile costs 40 percent more than the GTX 1080 and performs—in GPU limited scenarios—about 30-35 percent faster. \nBut there's no getting past the fact that the GTX 1080 Ti is still an extremely expensive graphics card. $700 is roughly the same price as our budget gaming PC , for example, which still includes a very capable RX 480 graphics card. This is definitely a gaming powerhouse of a graphics card, and it's designed for people that want to play 1440p 144Hz or 4K 60Hz, or even one of the upcoming 4K 120/144Hz HDR displays. If you've been holding onto an older GPU like the 780 Ti, waiting for the next high-end-but-not-Titan graphics card, it's now here. \nIf you're a computing/gaming enthusiast with deep pockets, the GTX 1080 Ti is now the card to get. I couldn't quite bring myself to recommend anyone go out and buy a Titan XP—mostly because we all knew the 1080 Ti was coming, and we knew it would at least come close to Titan XP performance at a much better price. Well, now it's here and it's not just close to the Titan XP, it has specs that actually exceed the XP in most areas. With many new games failing to support SLI/CrossFire, I usually recommend getting the fastest single GPU you can afford. If you're willing to spend $700 on graphics, the 1080 Ti is easily the best choice. ABOUT THE AUTHOR Jarred Walton Jarred got his start with computers on a Commodore 64, where he has fond memories of playing the early AD&D Gold Box games from SSI. After spending time studying computer science and working in the IT industry, he discovered a knack for journalism, which he’s been doing for more than a decade. This enables him to play with (aka “test”) all of the latest and greatest hardware; it’s a tough life, but someone has to do it. For science. Topics", "external_links": [], "published": "2017-03-09T21:00:00.000+02:00", "crawled": "2017-03-09T20:29:33.647+02:00", "highlightTitle": ""}