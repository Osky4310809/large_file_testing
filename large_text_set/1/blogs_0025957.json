{"organizations": [], "uuid": "0433b14d176a3ff1adaa16a66f4c161b3fc32bb9", "thread": {"social": {"gplus": {"shares": 66}, "pinterest": {"shares": 13}, "vk": {"shares": 0}, "linkedin": {"shares": 181}, "facebook": {"likes": 135, "shares": 135, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "moz.com", "main_image": "https://d1avok0lzls2w.cloudfront.net/uploads/og_image/588a691940e1e9.68732954.png", "site_section": "http://feeds.feedburner.com/seomoz", "section_title": "Moz Blog", "url": "https://moz.com/blog/google-search-console-webmaster-tools-reliability", "country": "US", "domain_rank": 1643, "title": "Google Search Console Reliability: Webmaster Tools on Trial", "performance_score": 1, "site": "moz.com", "participants_count": 1, "title_full": "Google Search Console Reliability: Webmaster Tools on Trial", "spam_score": 0.0, "site_type": "blogs", "published": "2017-01-31T07:03:00.000+02:00", "replies_count": 0, "uuid": "0433b14d176a3ff1adaa16a66f4c161b3fc32bb9"}, "author": "rjonesx.", "url": "https://moz.com/blog/google-search-console-webmaster-tools-reliability", "ord_in_thread": 0, "title": "Google Search Console Reliability: Webmaster Tools on Trial", "locations": [], "entities": {"persons": [{"name": "ahrefs", "sentiment": "none"}, {"name": "moz", "sentiment": "none"}, {"name": "googlebot", "sentiment": "none"}], "locations": [], "organizations": [{"name": "google", "sentiment": "negative"}, {"name": "gsc", "sentiment": "none"}, {"name": "external links", "sentiment": "none"}, {"name": "google search console", "sentiment": "none"}, {"name": "google analytics", "sentiment": "none"}, {"name": "search analytics  search analytics", "sentiment": "none"}, {"name": "internal links", "sentiment": "none"}, {"name": "search analytics", "sentiment": "none"}]}, "highlightText": "", "language": "english", "persons": [], "text": "0 \nThere are a handful of data sources relied upon by nearly every search engine optimizer. Google Search Console (formerly Google Webmaster Tools) has perhaps become the most ubiquitous. There are simply some things you can do with GSC, like disavowing links, that cannot be accomplished anywhere else, so we are in some ways forced to rely upon it. But, like all sources of knowledge, we must put it to the test to determine its trustworthiness — can we stake our craft on its recommendations? Let's see if we can pull back the curtain on GSC data and determine, once and for all, how skeptical we should be of the data it provides. Testing data sources \nBefore we dive in, I think it is worth having a quick discussion about how we might address this problem. There are basically two concepts that I want to introduce for the sake of this analysis: internal validity and external validity. \nInternal validity refers to whether the data accurately represents what Google knows about your site. \nExternal validity refers to whether the data accurately represents the web. \nThese two concepts are extremely important for our discussion. Depending upon the problem we are addressing as SEOs, we may care more about one or another. For example, let's assume that page speed was an incredibly important ranking factor and we wanted to help a customer. We would likely be concerned with the internal validity of GSC's \"time spent downloading a page\" metric because, regardless of what happens to a real user, if Google thinks the page is slow, we will lose rankings. We would rely on this metric insofar as we were confident it represented what Google believes about the customer's site. On the other hand, if we are trying to prevent Google from finding bad links, we would be concerned about the external validity of the \"links to your site\" section because, while Google might already know about some bad links, we want to make sure there aren't any others that Google could stumble upon. Thus, depending on how well GSC's sample links comprehensively describe the links across the web, we might reject that metric and use a combination of other sources (like Open Site Explorer , Majestic , and Ahrefs ) which will give us greater coverage. \nThe point of this exercise is simply to say that we can judge GSC's data from multiple perspectives, and it is important to tease these out so we know when it is reasonable to rely upon GSC . GSC Section 1: HTML Improvements \nOf the many useful features in GSC, Google provides a list of some common HTML errors it discovered in the course of crawling your site. This section, located at Search Appearance > HTML Improvements , lists off several potential errors including Duplicate Titles, Duplicate Descriptions, and other actionable recommendations. Fortunately, this first example gives us an opportunity to outline methods for testing both the internal and external validity of the data. As you can see in the screenshot below, GSC has found duplicate meta descriptions because a website has case insensitive URLs and no canonical tag or redirect to fix it. Essentially, you can reach the page from either /Page.aspx or /page.aspx, and this is apparent as Googlebot had found the URL both with and without capitalization. Let's test Google's recommendation to see if it is externally and internally valid. \nExternal Validity: In this case, the external validity is simply whether the data accurately reflects pages as they appear on the Internet. As one can imagine, the list of HTML improvements can be woefully out of date dependent upon the crawl rate of your site. In this case, the site had previously repaired the issue with a 301 redirect. \nThis really isn't terribly surprising. Google shouldn't be expected to update this section of GSC every time you apply a correction to your website. However, it does illustrate a common problem with GSC. Many of the issues GSC alerts you to may have already been fixed by you or your web developer. I don't think this is a fault with GSC by any stretch of the imagination, just a limitation that can only be addressed by more frequent, deliberate crawls like Moz Pro's Crawl Audit or a standalone tool like Screaming Frog . \nInternal Validity: This is where things start to get interesting. While it is unsurprising that Google doesn't crawl your site so frequently as to capture updates to your site in real-time, it is reasonable to expect that what Google has crawled would be reflected accurately in GSC. This doesn't appear to be the case. \nBy executing an info:http://concerning-url query in Google with upper-case letters, we can determine some information about what Google knows about the URL. Google returns results for the lower-case version of the URL! This indicates that Google both knows about the 301 redirect correcting the problem and has corrected it in their search index. As you can imagine, this presents us with quite a problem. HTML Improvement recommendations in GSC not only may not reflect changes you made to your site, it might not even reflect corrections Google is already aware of. Given this difference, it almost always makes sense to crawl your site for these types of issues in addition to using GSC . GSC Section 2: Index Status \nThe next metric we are going to tackle is Google's Index Status, which is supposed to provide you with an accurate number of pages Google has indexed from your site. This section is located at Google Index > Index Status. This particular metric can only be tested for internal validity since it is specifically providing us with information about Google itself. There are a couple of ways we could address this... We could compare the number provided in GSC to site: commands We could compare the number provided in GSC to the number of internal links to the homepage in the internal links section (assuming 1 link to homepage from every page on the site) \nWe opted for both. The biggest problem with this particular metric is being certain what it is measuring. Because GSC allows you to authorize the http, https, www, and non-www version of your site independently, it can be confusing as to what is included in the Index Status metric. \nWe found that when carefully applied to ensure no crossover of varying types (https vs http, www vs non-www), the Index Status metric seemed to be quite well correlated with the site:site.com query in Google, especially on smaller sites. The larger the site, the more fluctuation we saw in these numbers, but this could be accounted for by approximations performed by the site: command. \nWe found the link count method to be difficult to use, though. Consider the graphic above. The site in question has 1,587 pages indexed according to GSC, but the home page to that site has 7,080 internal links. This seems highly unrealistic, as we were unable to find a single page, much less the majority of pages, with 4 or more links back to the home page. However, given the consistency with the site: command and GSC's Index Status, I believe this is more of a problem with the way internal links are represented than with the Index Status metric. \nI think it is safe to conclude that the Index Status metric is probably the most reliable one available to us in regards to the number of pages actually included in Google's index. GSC Section 3: Internal Links \nThe Internal Links section found under Search Traffic > Internal Links seems to be rarely used, but can be quite insightful. If External Links tells Google what others think is important on your site, then Internal Links tell Google what you think is important on your site. This section once again serves as a useful example of knowing the difference between what Google believes about your site and what is actually true of your site. \nTesting this metric was fairly straightforward. We took the internal links numbers provided by GSC and compared them to full site crawls. We could then determine whether Google's crawl was fairly representative of the actual site. \nGenerally speaking, the two were modestly correlated with some fairly significant deviation. As an SEO, I find this incredibly important. Google does not start at your home page and crawl your site in the same way that your standard site crawlers do (like the one included in Moz Pro). Googlebot approaches your site via a combination of external links, internal links, sitemaps, redirects, etc. that can give a very different picture. In fact, we found several examples where a full site crawl unearthed hundreds of internal links that Googlebot had missed. Navigational pages, like category pages in the blog, were crawled less frequently, so certain pages didn't accumulate nearly as many links in GSC as one would have expected having looked only at a traditional crawl. \nAs search marketers, in this case we must be concerned with internal validity , or what Google believes about our site. I highly recommend comparing Google's numbers to your own site crawl to determine if there is important content which Google determines you have ignored in your internal linking. GSC Section 4: Links to Your Site \nLink data is always one of the most sought-after metrics in our industry, and rightly so. External links continue to be the strongest predictive factor for rankings and Google has admitted as much time and time again. So how does GSC's link data measure up? \nIn this analysis, we compared the links presented to us by GSC to those presented by Ahrefs, Majestic, and Moz for whether those links are still live. To be fair to GSC, which provides only a sampling of links, we only used sites that had fewer than 1,000 total backlinks, increasing the likelihood that we get a full picture (or at least close to it) from GSC. The results are startling. GSC's lists, both \"sample links\" and \"latest links,\" were the lowest-performing in terms of \"live links\" for every site we tested, never once beating out Moz, Majestic, or Ahrefs. \nI do want to be clear and upfront about Moz's performance in this particular test. Because Moz has a smaller total index, it is likely we only surface higher-quality, long-lasting links. Our out-performing Majestic and Ahrefs by just a couple of percentage points is likely a side effect of index size and not reflective of a substantial difference. However, the several percentage points which separate GSC from all 3 link indexes cannot be ignored. In terms of external validity — that is to say, how well this data reflects what is actually happening on the web — GSC is out-performed by third-party indexes. \nBut what about internal validity ? Does GSC give us a fresh look at Google's actual backlink index? It does appear that the two are consistent insofar as rarely reporting links that Google is already aware are no longer in the index. We randomly selected hundreds of URLs which were \"no longer found\" according to our test to determine if Googlebot still had old versions cached and, uniformly, that was the case. While we can't be certain that it shows a complete set of Google's link index relative to your site, we can be confident that Google tends to show only results that are in accord with their latest data. GSC Section 5: Search Analytics \nSearch Analytics is probably the most important and heavily utilized feature within Google Search Console, as it gives us some insight into the data lost with Google's \"Not Provided\" updates to Google Analytics. Many have rightfully questioned the accuracy of the data, so we decided to take a closer look. Experimental analysis \nThe Search Analytics section gave us a unique opportunity to utilize an experimental design to determine the reliability of the data. Unlike some of the other metrics we tested, we could control reality by delivering clicks under certain circumstances to individual pages on a site. We developed a study that worked something like this: Create a series of nonsensical text pages. Link to them from internal sources to encourage indexation. Use volunteers to perform searches for the nonsensical terms, which inevitably reveal the exact-match nonsensical content we created. Vary the circumstances under which those volunteers search to determine if GSC tracks clicks and impressions only in certain environments. Use volunteers to click on those results. Record their actions. Compare to the data provided by GSC. \nWe decided to check 5 different environments for their reliability: User performs search logged into Google in Chrome User performs search logged out, incognito in Chrome User performs search from mobile User performs search logged out in Firefox User performs the same search 5 times over the course of a day \nWe hoped these variants would answer specific questions about the methods Google used to collect data for GSC. We were sorely and uniformly disappointed. Experimental results", "external_links": [], "published": "2017-01-31T07:03:00.000+02:00", "crawled": "2017-01-31T10:40:50.227+02:00", "highlightTitle": ""}