{"organizations": [], "uuid": "bc2c2ef311edc9f142f56b8de57f685bff7d8817", "thread": {"social": {"gplus": {"shares": 7}, "pinterest": {"shares": 1}, "vk": {"shares": 0}, "linkedin": {"shares": 52}, "facebook": {"likes": 155, "shares": 155, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "www.fastcompany.com", "main_image": "https://fast-company-res.cloudinary.com/image/upload/fc/3068907-poster-p-1-equirectproblems.jpg", "site_section": "http://feeds.feedburner.com/fastcompany/headlines", "section_title": "Fast Company", "url": "https://www.fastcompany.com/3068907/how-youtube-is-making-virtual-reality-look-better", "country": "US", "domain_rank": 3157, "title": "How YouTube Is Making Virtual Reality Look Better", "performance_score": 1, "site": "fastcompany.com", "participants_count": 1, "title_full": "How YouTube Is Making Virtual Reality Look Better", "spam_score": 0.0, "site_type": "blogs", "published": "2017-03-14T05:30:00.000+02:00", "replies_count": 0, "uuid": "bc2c2ef311edc9f142f56b8de57f685bff7d8817"}, "author": "Daniel Terdiman", "url": "https://www.fastcompany.com/3068907/how-youtube-is-making-virtual-reality-look-better", "ord_in_thread": 0, "title": "How YouTube Is Making Virtual Reality Look Better", "locations": [], "entities": {"persons": [{"name": "anjali wheeler", "sentiment": "none"}, {"name": "van hoff", "sentiment": "none"}, {"name": "batt", "sentiment": "none"}, {"name": "arthur van hoff", "sentiment": "none"}, {"name": "wheeler", "sentiment": "none"}, {"name": "anthony batt", "sentiment": "none"}, {"name": "daniel terdiman", "sentiment": "none"}, {"name": "wevr", "sentiment": "none"}, {"name": "daniel", "sentiment": "none"}], "locations": [{"name": "earth", "sentiment": "none"}, {"name": "wevr", "sentiment": "none"}], "organizations": [{"name": "fast company daily newsletter", "sentiment": "none"}, {"name": "time", "sentiment": "none"}, {"name": "github", "sentiment": "none"}, {"name": "equiangular", "sentiment": "none"}, {"name": "cto", "sentiment": "none"}, {"name": "cnet", "sentiment": "none"}, {"name": "google", "sentiment": "none"}, {"name": "youtube", "sentiment": "none"}, {"name": "samsung", "sentiment": "none"}, {"name": "new york times", "sentiment": "none"}]}, "highlightText": "", "language": "english", "persons": [], "text": "  3 minute Read innovation agents How YouTube Is Making Virtual Reality Look Better The Google-owned service has borrowed a page from the video-game industry to make the most-viewed areas of the screen clearer. Images: courtesy of Youtube By Daniel Terdiman 03.13.17 | 6:30 pm \nYouTube has developed what it hopes can become a new industry standard that makes 360-degree videos look better and perform more efficiently. \nThe technological update, which YouTube and Google’s internal Daydream virtual reality team have already implemented for displaying 360-degree videos on Android devices, was created to address a problem that would be familiar to anyone who’s ever tried to lay out a spherical object on a rectangle. Think: showing the Earth on a rectangular map, which vastly distorts the size of various continents. \nWith 360 videos, like those you might watch on a Samsung Gear VR or Google’s own Daydream View, the problem manifests in the way viewers see the content: the highest-quality areas of the screen are the areas–the very top or bottom, and the corners–where the viewer is least likely to look. \nThe goal over the last year, according to YouTube software engineer Anjali Wheeler, has been to come up with a system that displays the best-quality parts of the imagery in the center of the viewer’s gaze. YouTube, which has increasingly become a home for 360-degree video, has finally achieved it, Wheeler said. Known by the wonky term “equiangular cube map,” the new system has successfully managed to place more of the highest-quality pixels in 360 videos in the most-viewed areas of the screen. \nIt’s worth noting that individual viewers may have trouble identifying the difference in quality, but she argued that what users see when watching YouTube 360 videos on Android devices now feels less blurry and therefore is easier to watch over time. \nThe basic solution to the problem—the use of what’s called a cube map—has long been in use in the video-game industry. In that system, the most wasted real estate, having high-quality pixels at the very top or bottom of the screen, is avoided altogether. But it still results in poor-quality areas in the center of the viewing space. Cube map \n“As opposed to traditional cube map, which distributes equal pixels for equal distances on the cube surface,” YouTube wrote in a draft blog post, “equiangular cube map distributes equal pixels for equal angular change.” \nIn layman’s terms, that means that the viewer now sees more pixels in the center, making the display more consistent. “We feel almost all areas become uniformly better,” says Wheeler. Equiangular cube map \nFor virtual reality content creators, the innovation is a step forward, albeit an “iterative” one, says Anthony Batt, a cofounder and executive vice president at Wevr , a leading VR developer and distributor. \n“At the high level, I think that the consumer will potentially see more pixels packed where the creator, like myself, will want them,” Batt says. Equiangular cube map projection “can push pixels where you want. But the devil’s in the details.” \nBatt says Wevr has been using a similar approach in its own content creation for some time, but lauded Google and YouTube for “innovative” steps forward that he thinks is “actually good news for our industry.” \nArthur van Hoff, cofounder and CTO of Jaunt , another leading VR content creator and distributor, notes that, “We are always happy to see the wide adoption of industry standards that ultimately improve the user experience, and we appreciate YouTube leveraging their platform to help in that effort.” \nAdds van Hoff, Jaunt has “been using a similar but proprietary approach for the past four years and has found great success with that method.” \nFor YouTube and Google, the next step is helping to turn what it’s already created into an industry standard. To that end, they’ve created what they call a projection independent mesh. In short, that is designed to instruct video rendering software packages to render 360-degree imagery as specified, “and does not need to understand the details of the projection used,” YouTube and Google wrote in their draft post. They have published that standard on GitHub and hope industry experts will comment on it and potentially improve upon it. \nAccording to Batt, Wevr may well do just that. About the author Daniel Terdiman is a San Francisco-based technology journalist with nearly 20 years of experience.A veteran of CNET and VentureBeat , Daniel has also written for Wired, The New York Times, Time, and many other publications. Fast Company Daily Newsletter: Get our best stories delivered to your inbox. Sign Up", "external_links": [], "published": "2017-03-14T05:30:00.000+02:00", "crawled": "2017-03-14T12:09:23.572+02:00", "highlightTitle": ""}