{"organizations": [], "uuid": "8e3c8f26ceed422583e5214f6635f389a4e68e3a", "thread": {"social": {"gplus": {"shares": 3}, "pinterest": {"shares": 4}, "vk": {"shares": 0}, "linkedin": {"shares": 13}, "facebook": {"likes": 110, "shares": 110, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "spectrum.ieee.org", "main_image": "", "site_section": "http://spectrum.ieee.org", "section_title": "IEEE Spectrum Recent Content full text", "url": "http://spectrum.ieee.org/automaton/robotics/home-robots/wagging-tails-help-robots-communicate", "country": "US", "domain_rank": 1895, "title": "Wagging Tails Help Robots Communicate With Humans", "performance_score": 1, "site": "ieee.org", "participants_count": 1, "title_full": "Wagging Tails Help Robots Communicate With Humans", "spam_score": 0.0, "site_type": "blogs", "published": "2017-02-17T05:25:00.000+02:00", "replies_count": 0, "uuid": "8e3c8f26ceed422583e5214f6635f389a4e68e3a"}, "author": "", "url": "http://spectrum.ieee.org/automaton/robotics/home-robots/wagging-tails-help-robots-communicate", "ord_in_thread": 0, "title": "Wagging Tails Help Robots Communicate With Humans", "locations": [], "entities": {"persons": [], "locations": [], "organizations": []}, "highlightText": "", "language": "english", "persons": [], "text": "Giving a Roomba a tail makes it easy for humans to understand its \"feelings\" Image: University of Manitoba HCI Lab \"Wait, is that a tail on that Roomba??\" I have no idea what my Roomba is doing most of the time when it runs. It’s vacuuming, I know that, but sometimes it just sits there for a little bit, or slowly swivels back and forth, or does something else that doesn’t seem (strictly speaking) vacuuming related. This isn’t as much of a problem for Roombas specifically, but for robotics in general, it can be: If robots are bad at communicating what’s going on with them, it’ll be harder for people to accept them in our daily lives.\nOne thing that lets humans instantly grasp the abstract internal state of other humans is we look at each other’s faces. Now, as you can imagine, giving robots human faces can lead to other problems . The good news is we’re also hardwired to perform this intuitive abstract internal state reading trick on some other expressive living things, like dogs: When we look at a dog’s tail, we get an indication of whether it’s happy or not. It turns out that we can do the same for robots, as long as you can give them a tail.\nImage: University of Manitoba HCI Lab iRobot Create equipped with an actuated, fluffy tail that it can wag like a dog. A few years ago, University of Manitoba undergraduate student Ashish Singh and professor James E. Young decided to investigate whether people could accurately interpret the “feelings” of a Roomba with an actuated, fluffy tail that it could wag like a dog. The Roomba doesn’t have feelings, of course, but acting “happy” could mean that all systems are okay, while “sad” could communicate a problem and “tired” could mean a low battery state. In results published in 2013, they found out that it works:\n\nPlus, your floor gets an extra dusting!\n“The useful component of emotional interfaces is in how easily, and quickly, people can interpret them,” Young told us. “As social beings, we are very experienced at quickly reading emotional states, which provide us coarse-grained insight into the state of others.” And while he said they initially considered many alternatives, a dog-like tail “seemed to be a nice, clear choice—even people without dogs or cats may be able to read some tail motions, so we decided to formally investigate that.”\nImage: Ashish Singh Young added that one of the goals of the project was exploring the notion of “peripheral awareness.” “With a dog tail that projects a robot’s state, you could be preparing dinner and just see the robot going by from the corner of your eye,” he said. That would let you quickly know how the robot is doing, whereas a screen would probably require training to understand and sound would be intrusive. \nWhen they started, the researchers weren’t sure how readily people would be able to read emotions from a robot with a tail, and it wasn’t clear how consistent this would be across a diverse group of people (if at all). Results of the study showed that people have no trouble reliably reading emotional states from a robotic tail. The researchers checked to see whether study participants had pets of their own, and it turned out not to make a difference at all: Whether or not you are (or ever have been) a dog owner, you can still understand what different kinds of tail wagging mean.\nThe results were so consistent that the researchers were able to create a set of design guidelines that map out exactly what tail motions you’d use to communicate. Want your robot to express disdain? That’s a continuous vertical wag at medium speed. Want it to seemed overwhelmed? Try some high speed circular wagging. The results were so consistent, in fact, that the researchers were able to create a set of design guidelines that formally map out exactly what tail motions you’d use to communicate. Want your robot to express disdain? That’s a continuous vertical wag at medium speed. Want it to seemed overwhelmed? Try some high speed circular wagging. From “awed” to “modest” to “joyful” to “astonished,” there are specific tail motions that a robot can use to communicate. “Any current robot that works with people, including factory transport robots, emerging domestic robots, even collocated utility robots such as the PackBot, could benefit from this,” Young said .\nAfter the tailed Roomba project, Young’s group has looked at how a tail might work on a humanoid robot, and it has also done more in-depth experiments with different varieties of robot communication, like how drones can alter their motion paths to show that they’re “tired” or “excited.” All of this research is available at the lab’s website linked below, along with guidelines for expression using a tail, just in case you’re ready to add one to your robot.\n[ A Dog Tail for Robots ] via [ University of Manitoba HCI Lab ]\nSpecial thanks to @grok_ and @Straithe ! \n", "external_links": [], "published": "2017-02-17T05:25:00.000+02:00", "crawled": "2017-02-17T00:34:40.697+02:00", "highlightTitle": ""}